{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSbT0qBSukCTw6vDtRxmXy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tahawarsi360/NLP_assignment/blob/main/AUTOCOMPLETE_using_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "MwIJ7l_y3jHf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample sentences for training\n",
        "sentences = [\n",
        "    \"I love coding\",\n",
        "    \"Coding is fun\",\n",
        "    \"Python is a popular programming language\",\n",
        "    \"Machine learning is an exciting field\",\n",
        "    \"Artificial intelligence is the future\",\n",
        "    \"Programming is a valuable skill\",\n",
        "    \"Data science is in high demand\",\n",
        "    \"Web development is constantly evolving\",\n",
        "    \"Algorithms are the heart of computer science\",\n",
        "    \"Software engineering drives innovation\",\n",
        "    \"Technology shapes our lives\",\n",
        "    \"The internet connects the world\",\n",
        "    \"Cybersecurity is crucial in the digital age\",\n",
        "    \"Mobile apps have revolutionized industries\",\n",
        "    \"Cloud computing enables scalable solutions\",\n",
        "    \"Big data analytics uncovers hidden insights\",\n",
        "]"
      ],
      "metadata": {
        "id": "R3v6XFW53pLI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate training data\n",
        "X_train = []\n",
        "y_train = []\n",
        "for sentence in sentences:\n",
        "    for i in range(1, len(sentence)):\n",
        "        X_train.append(sentence[:i])\n",
        "        y_train.append(sentence[i])"
      ],
      "metadata": {
        "id": "6MZhU_pw3u4s"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert sentences to numerical representation\n",
        "char_to_index = {char: i for i, char in enumerate(set(''.join(sentences)))}\n",
        "index_to_char = {i: char for char, i in char_to_index.items()}\n",
        "X_train = [[char_to_index[char] for char in sentence] for sentence in X_train]\n",
        "X_train = pad_sequences(X_train)\n",
        "y_train = np.array([char_to_index[char] for char in y_train])"
      ],
      "metadata": {
        "id": "bKMfcsVg37pQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape input data for LSTM\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
      ],
      "metadata": {
        "id": "yV1GoRP74DUm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dense(len(char_to_index), activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "aRBgHjPC4Gvj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32)"
      ],
      "metadata": {
        "id": "vkxahChA4QB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate auto-completions\n",
        "def generate_auto_completions(seed_text, num_chars):\n",
        "    generated_text = seed_text\n",
        "    for _ in range(num_chars):\n",
        "        x = np.array([[char_to_index[char] for char in seed_text]])\n",
        "        x = pad_sequences(x, maxlen=X_train.shape[1])\n",
        "        x = np.reshape(x, (1, x.shape[1], 1))\n",
        "        prediction = model.predict(x, verbose=0)\n",
        "        index = np.argmax(prediction)\n",
        "        char = index_to_char[index]\n",
        "        generated_text += char\n",
        "        seed_text += char\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "h9ksuMIO4X0M"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3o_vHnD2l5b",
        "outputId": "04db5ffc-4113-40c3-913a-0ed87e97e684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Auto-completion: I love machine  ing es s\n"
          ]
        }
      ],
      "source": [
        "# Test the auto-completion\n",
        "seed_text = \"I love machine\"\n",
        "num_chars = 10\n",
        "completion = generate_auto_completions(seed_text, num_chars)\n",
        "print(f\"Auto-completion: {completion}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output you're seeing might not make much sense because the model is trained on short prefixes of sentences and predicts the next character based on those prefixes. It does not have a comprehensive understanding of grammar or context.\n",
        "\n",
        "To improve the output and make it more coherent, you can consider the following suggestions:\n",
        "\n",
        "Increase the training data: Adding more varied and representative sentences to the training data can help the model learn a wider range of patterns and contexts.\n",
        "\n",
        "Use a larger and more complex model: You can increase the capacity of the LSTM model by adding more LSTM layers or increasing the number of LSTM units. This can potentially capture more intricate patterns and dependencies in the data.\n",
        "\n",
        "Train for more epochs: Training the model for a longer duration allows it to refine its predictions and improve performance. You can increase the number of epochs and monitor the loss to avoid overfitting.\n",
        "\n",
        "Adjust the hyperparameters: Experiment with different hyperparameter settings, such as the learning rate, batch size, or LSTM layer size, to find the configuration that works best for your data.\n",
        "\n",
        "Use a language model pre-trained on a larger corpus: Instead of training your own LSTM model from scratch, you can use pre-trained language models such as GPT-3, GPT-2, or BERT, which have been trained on massive amounts of text data. These models typically offer better language understanding and can generate more coherent completions.\n",
        "\n",
        "Remember that while LSTM models can generate auto-completions, they may still produce outputs that are not always coherent or grammatically correct. Generating meaningful and contextually appropriate completions is a challenging task, and the quality of the output depends on various factors, including the size and diversity of the training data and the complexity of the model architecture."
      ],
      "metadata": {
        "id": "hNG9Oukl56zL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we first define a list of sample sentences for training. Then, we generate training data by splitting each sentence into input-output pairs, where the input is a prefix of the sentence and the output is the next character in the sentence. We convert the characters to numerical representation using a character-to-index mapping.\n",
        "\n",
        "Next, we build the LSTM model using the Keras Sequential API. The model consists of an LSTM layer followed by a dense layer with softmax activation. We compile the model with the sparse categorical cross-entropy loss and the Adam optimizer.\n",
        "\n",
        "After that, we train the model on the training data.\n",
        "\n",
        "To generate auto-completions, we define a function generate_auto_completions() that takes a seed text and the number of characters to generate. The function iteratively predicts the next character based on the seed text and appends it to the generated text. Finally, it returns the generated text.\n",
        "\n",
        "We test the auto-completion by providing a seed text \"I love\" and generating 10 characters.\n",
        "\n",
        "Note that this is a basic example, and you can modify and improve the model according to your specific requirements and dataset."
      ],
      "metadata": {
        "id": "d0m-4fMs3A9b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sIWSQoVC26bR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}